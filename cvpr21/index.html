<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<base target="_blank">
	<meta name="keywords" content="" />
	<meta name="description" content="" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<title>Lele Chen's personal webpage</title>
	<link href="./css/bootstrap.min.css" rel="stylesheet">
	<link href="http://fonts.googleapis.com/css?family=Arvo" rel="stylesheet" type="text/css" />
	<link rel="stylesheet" type="text/css" href="./css/style.css" />
	<!-- <link rel="stylesheet" type="text/css" href="../css/my.css"> -->
	<link rel="stylesheet" type="text/css" href="./css/project.css">
	<!-- <link href="css/agency.css" rel="stylesheet"> -->
</head>

<body>
	<div id="bg">
		<div id="outer">

			<div id="main">
				<div id="content">
					<div class="box">
						<div id="conference">
							CVPR 2021
						</div>
						<div id="title">
							High-fidelity Face Tracking for AR/VR via Deep Lighting Adaptation
						</div>
						<div id="project_author">
							<ul class="list-inline">
								<li class="author"> <a href="https://www.cs.rochester.edu/u/lchen63/">Lele Chen </a>
									<sup>1</sup>
								</li>
								<li class="author"> <a href="https://sites.google.com/site/zjucaochen/home">Chen Cao</a>
									<sup>2 </sup>
								</li>
								<li class="author"> <a href="https://www.cs.cmu.edu/~ftorre/">Fernando De la Torre</a>
									<sup>2 </sup>
								</li>
									<li class="author"> <a href="https://scholar.google.com/citations?user=ss-IvjMAAAAJ&hl=en">Jason Saragih</a>
									<sup>2</sup>
								</li>
								<li class="author"> <a href="https://www.cs.rochester.edu/~cxu22/">Chenliang Xu</a>
									<sup>1</sup>
								</li>
						
								<li class="author"> <a href="http://www.cs.cmu.edu/~yaser/">Yaser Sheikh</a>
									<sup>2</sup>
								</li>

							</ul>
						</div>
						<div class="institute">
							<ul class="list-inline">
								<li> <sup>1</sup> University of Rochester
								</li>
								<li> <sup>2</sup> Facebook Reality Labs
								</li>
							</ul>
						</div>
						
					</div>

					<div class="box">
						<div class="sec_title">
							Abstract
						</div>
						<div class="teaser">
							<img src="./cvpr2021.gif" width="90%" />
						</div>
						<br />
						<div class="abstract_text">
							<div class="description" style="line-height:1.5">
								3D video avatars can empower virtual communications
								by providing compression, privacy, entertainment, and a
								sense of presence in AR/VR. Best 3D photo-realistic AR/VR
								avatars driven by video, that can minimize uncanny effects,
								rely on person-specific models. However, existing personspecific photo-realistic 3D models are not robust to lighting,
								hence their results typically miss subtle facial behaviors and
								cause artifacts in the avatar. This is a major drawback for
								the scalability of these models in communication systems
								(e.g., Messenger, Skype, FaceTime) and AR/VR. This paper
								addresses previous limitations by learning a deep learning
								lighting model, that in combination with a high-quality 3D
								face tracking algorithm, provides a method for subtle and
								robust facial motion transfer from a regular video to a 3D
								photo-realistic avatar. Extensive experimental validation
								and comparisons to other state-of-the-art methods demonstrate the effectiveness of the proposed framework in realworld scenarios with variability in pose, expression, and
								illumination.
							</div>
						</div>
					</div>

					<div class="box">
						<div class="sec_title">
							Paper
						</div>
						<div class="teaser">
							<a
								href="https://www.cs.rochester.edu/u/lchen63/cvpr2021-arxiv.pdf">
								<img src="./paper.png" />
							</a>
						</div>
					</div>

					<div class="box">
						<div class="sec_title">
							Video
						</div>
						<div class="video">
							<iframe width="1062" height="600" src="https://www.youtube.com/embed/dtz1LgZR8cc" title="YouTube video player"
								frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
								allowfullscreen></iframe>
						</div>
					</div>



					<div class="box" id="last_box">
						<div class="sec_title">
							Citation
						</div>
						<div style="margin:auto;">
							<pre class="citation">
@InProceedings{Chen_2021_CVPR,
    author    = {Chen, Lele and Cao, Chen and De la Torre, Fernando and Saragih, Jason and Xu, Chenliang and Sheikh, Yaser},
    title     = {High-Fidelity Face Tracking for AR/VR via Deep Lighting Adaptation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {13059-13069}
}</pre>
						</div>
					</div>


					<br class="clear" />
				</div>
				<br class="clear" />
			</div>

		</div>
		
	</div>
</body>

</html>

